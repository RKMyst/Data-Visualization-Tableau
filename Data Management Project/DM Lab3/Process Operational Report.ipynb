{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab220b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been cleaned and saved to 'Cleaned_Operational_Report.csv'\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df_operational = pd.read_csv(\"Merged_Superstore.csv\")\n",
    "\n",
    "# Remove any duplicate rows (based on Order ID and Product ID)\n",
    "df_operational.drop_duplicates(subset=['Order ID', 'Product ID'], inplace=True)\n",
    "\n",
    "# Function to fill missing postal codes based on city reference\n",
    "def fill_missing_postal(row):\n",
    "    if pd.isnull(row['Postal Code']) and row['City'] in postal_ref:\n",
    "        return postal_ref[row['City']]\n",
    "    return row['Postal Code']\n",
    "\n",
    "# Create a reference dictionary of cities and their postal codes\n",
    "postal_ref = df_operational.dropna(subset=['Postal Code']).groupby('City')['Postal Code'].first().to_dict()\n",
    "\n",
    "# Fill in missing Postal Code values using the function\n",
    "df_operational['Postal Code'] = df_operational.apply(fill_missing_postal, axis=1)\n",
    "\n",
    "# Save cleaned data to CSV\n",
    "df_operational.to_csv(\"Cleaned_Operational_Report.csv\", index=False)\n",
    "\n",
    "print(\"Data has been cleaned and saved to 'Cleaned_Operational_Report.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec8cae6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataframes_by_year' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-678a01e017b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Export each year's data to a separate CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataframes_by_year\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcsv_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Superstore_Data_{year}.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Data for {year} saved to {csv_filename}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataframes_by_year' is not defined"
     ]
    }
   ],
   "source": [
    "# Export each year's data to a separate CSV file\n",
    "for year, df in dataframes_by_year.items():\n",
    "    csv_filename = f\"Superstore_Data_{year}.csv\"\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    print(f\"Data for {year} saved to {csv_filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc87e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Load the \"Cleaned_Operational_Report.csv\" file into a DataFrame\n",
    "df = pd.read_csv(\"Cleaned_Operational_Report.csv\")\n",
    "\n",
    "# Connect to an in-memory SQLite database\n",
    "conn = sqlite3.connect(':memory:')\n",
    "\n",
    "# Write the data to an SQLite table named \"cleaned_data\"\n",
    "df.to_sql('cleaned_data', conn, index=False, if_exists='replace')\n",
    "\n",
    "# Adjusted query to extract data sorted by \"Order Date\", excluding the specified columns\n",
    "query_final_adjusted = \"\"\"\n",
    "SELECT \n",
    "    `Order ID`, `Order Date`, `Ship Date`, `Ship Mode`, `Customer Name`, \n",
    "    Segment, City, State, `Postal Code`, Region, Category, \n",
    "    Sales, Quantity, Discount, Profit, Returned\n",
    "FROM cleaned_data\n",
    "ORDER BY `Order Date`\n",
    "\"\"\"\n",
    "\n",
    "# Execute the adjusted query and store the result in a DataFrame\n",
    "df_final_adjusted_extracted = pd.read_sql(query_final_adjusted, conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58228e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Order ID  Order Date   Ship Date       Ship Mode  Customer Name  \\\n",
      "0  CA-2018-103800  2018-01-03  2018-01-07  Standard Class  Darren Powers   \n",
      "1  CA-2018-112326  2018-01-04  2018-01-08  Standard Class  Phillina Ober   \n",
      "2  CA-2018-112326  2018-01-04  2018-01-08  Standard Class  Phillina Ober   \n",
      "3  CA-2018-112326  2018-01-04  2018-01-08  Standard Class  Phillina Ober   \n",
      "4  CA-2018-141817  2018-01-05  2018-01-12  Standard Class     Mick Brown   \n",
      "\n",
      "       Segment          City         State  Postal Code   Region  \\\n",
      "0     Consumer       Houston         Texas      77095.0  Central   \n",
      "1  Home Office    Naperville      Illinois      60540.0  Central   \n",
      "2  Home Office    Naperville      Illinois      60540.0  Central   \n",
      "3  Home Office    Naperville      Illinois      60540.0  Central   \n",
      "4     Consumer  Philadelphia  Pennsylvania      19143.0     East   \n",
      "\n",
      "          Category    Sales  Quantity  Discount   Profit  Returned  \n",
      "0  Office Supplies   16.448         2       0.2   5.5512         0  \n",
      "1  Office Supplies   11.784         3       0.2   4.2717         0  \n",
      "2  Office Supplies  272.736         3       0.2 -64.7748         0  \n",
      "3  Office Supplies    3.540         2       0.8  -5.4870         0  \n",
      "4  Office Supplies   19.536         3       0.2   4.8840         0  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the final extracted data\n",
    "print(df_final_adjusted_extracted.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "210ec2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Order ID  Order Date   Ship Date       Ship Mode  Customer Name  \\\n",
      "0  CA-2018-103800  2018-01-03  2018-01-07  Standard Class  Darren Powers   \n",
      "1  CA-2018-112326  2018-01-04  2018-01-08  Standard Class  Phillina Ober   \n",
      "2  CA-2018-112326  2018-01-04  2018-01-08  Standard Class  Phillina Ober   \n",
      "3  CA-2018-112326  2018-01-04  2018-01-08  Standard Class  Phillina Ober   \n",
      "4  CA-2018-141817  2018-01-05  2018-01-12  Standard Class     Mick Brown   \n",
      "\n",
      "       Segment          City         State  Postal Code   Region  \\\n",
      "0     Consumer       Houston         Texas      77095.0  Central   \n",
      "1  Home Office    Naperville      Illinois      60540.0  Central   \n",
      "2  Home Office    Naperville      Illinois      60540.0  Central   \n",
      "3  Home Office    Naperville      Illinois      60540.0  Central   \n",
      "4     Consumer  Philadelphia  Pennsylvania      19143.0     East   \n",
      "\n",
      "          Category    Sales  Quantity  Discount   Profit  Returned  \\\n",
      "0  Office Supplies   16.448         2       0.2   5.5512         0   \n",
      "1  Office Supplies   11.784         3       0.2   4.2717         0   \n",
      "2  Office Supplies  272.736         3       0.2 -64.7748         0   \n",
      "3  Office Supplies    3.540         2       0.8  -5.4870         0   \n",
      "4  Office Supplies   19.536         3       0.2   4.8840         0   \n",
      "\n",
      "   Delivery Days  \n",
      "0              4  \n",
      "1              4  \n",
      "2              4  \n",
      "3              4  \n",
      "4              7  \n"
     ]
    }
   ],
   "source": [
    "# Calculate the delivery days\n",
    "df_final_adjusted_extracted['Delivery Days'] = (pd.to_datetime(df_final_adjusted_extracted['Ship Date']) \n",
    "                                               - pd.to_datetime(df_final_adjusted_extracted['Order Date'])).dt.days\n",
    "\n",
    "# Display the first few rows to check the new column\n",
    "print(df_final_adjusted_extracted.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bc7e024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to 'Final_Superstore_Data.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-9e2f9677eb32>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final_adjusted_extracted['COGS'] = df_final_adjusted_extracted['Sales'] - df_final_adjusted_extracted['Profit']\n"
     ]
    }
   ],
   "source": [
    "# Rearrange the columns\n",
    "column_order = ['Order Date', 'Region', 'State', 'City', 'Category', 'Segment', 'Sales', 'Quantity', 'Discount', 'Profit', 'Returned', 'Delivery Days']\n",
    "df_final_adjusted_extracted = df_final_adjusted_extracted[column_order]\n",
    "\n",
    "# Add COGS and Margin columns\n",
    "df_final_adjusted_extracted['COGS'] = df_final_adjusted_extracted['Sales'] - df_final_adjusted_extracted['Profit']\n",
    "df_final_adjusted_extracted['Margin'] = (df_final_adjusted_extracted['Profit'] / df_final_adjusted_extracted['Sales']) * 100\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "df_final_adjusted_extracted.to_csv(\"Final_Superstore_Data.csv\", index=False)\n",
    "print(\"Data exported to 'Final_Superstore_Data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09f845ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KPIs exported to 'Adjusted_Yearly_KPIs.csv' and 'Adjusted_Quarterly_KPIs.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kei/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py:2779: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  sql.to_sql(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Load the \"Final_Superstore_Data.csv\" file into a DataFrame\n",
    "df = pd.read_csv(\"Final_Superstore_Data.csv\")\n",
    "\n",
    "# Connect to an SQLite database\n",
    "conn = sqlite3.connect(':memory:')\n",
    "\n",
    "# Write the DataFrame to an SQLite table\n",
    "df.to_sql('superstore_data', conn, index=False, if_exists='replace')\n",
    "\n",
    "# Add 'Year' and 'Quarter' columns to the DataFrame based on 'Order Date'\n",
    "df['Year'] = pd.to_datetime(df['Order Date']).dt.year\n",
    "df['Quarter'] = pd.to_datetime(df['Order Date']).dt.quarter\n",
    "\n",
    "# Update the SQLite table with the modified DataFrame\n",
    "df.to_sql('superstore_data', conn, index=False, if_exists='replace')\n",
    "\n",
    "# Calculate the KPIs year by year\n",
    "yearly_kpis_query = \"\"\"\n",
    "SELECT \n",
    "    Year,\n",
    "    SUM(Sales) as Total_Sales,\n",
    "    COUNT(*) as Total_Orders,\n",
    "    SUM(CASE WHEN Returned = 'Yes' THEN 1 ELSE 0 END) as Total_Returns,\n",
    "    (SUM(Sales) / COUNT(*)) as Sales_Performance,\n",
    "    (SUM(Sales) / ?) * 100 as Sales_Target_Attainment,\n",
    "    (SUM(CASE WHEN Returned = 'Yes' THEN 1 ELSE 0 END) * 1.0 / COUNT(*)) * 100 as Return_Rate\n",
    "FROM superstore_data\n",
    "GROUP BY Year\n",
    "ORDER BY Year\n",
    "\"\"\"\n",
    "yearly_kpis = pd.read_sql(yearly_kpis_query, conn, params=(avg_sales,))\n",
    "\n",
    "# Calculate the KPIs quarter by quarter\n",
    "quarterly_kpis_query = \"\"\"\n",
    "SELECT \n",
    "    Year,\n",
    "    Quarter,\n",
    "    SUM(Sales) as Total_Sales,\n",
    "    COUNT(*) as Total_Orders,\n",
    "    SUM(CASE WHEN Returned = 'Yes' THEN 1 ELSE 0 END) as Total_Returns,\n",
    "    (SUM(Sales) / COUNT(*)) as Sales_Performance,\n",
    "    (SUM(Sales) / ?) * 100 as Sales_Target_Attainment,\n",
    "    (SUM(CASE WHEN Returned = 'Yes' THEN 1 ELSE 0 END) * 1.0 / COUNT(*)) * 100 as Return_Rate\n",
    "FROM superstore_data\n",
    "GROUP BY Year, Quarter\n",
    "ORDER BY Year, Quarter\n",
    "\"\"\"\n",
    "quarterly_kpis = pd.read_sql(quarterly_kpis_query, conn, params=(avg_sales,))\n",
    "\n",
    "# Format the KPIs as percentages with two decimal places\n",
    "yearly_kpis['Sales_Performance'] = yearly_kpis['Sales_Performance'].map(\"{:,.2f}%\".format)\n",
    "yearly_kpis['Sales_Target_Attainment'] = yearly_kpis['Sales_Target_Attainment'].map(\"{:,.2f}%\".format)\n",
    "yearly_kpis['Return_Rate'] = yearly_kpis['Return_Rate'].map(\"{:,.2f}%\".format)\n",
    "\n",
    "quarterly_kpis['Sales_Performance'] = quarterly_kpis['Sales_Performance'].map(\"{:,.2f}%\".format)\n",
    "quarterly_kpis['Sales_Target_Attainment'] = quarterly_kpis['Sales_Target_Attainment'].map(\"{:,.2f}%\".format)\n",
    "quarterly_kpis['Return_Rate'] = quarterly_kpis['Return_Rate'].map(\"{:,.2f}%\".format)\n",
    "\n",
    "# Export the KPIs to CSV files\n",
    "yearly_kpis.to_csv(\"Adjusted_Yearly_KPIs.csv\", index=False)\n",
    "quarterly_kpis.to_csv(\"Adjusted_Quarterly_KPIs.csv\", index=False)\n",
    "\n",
    "print(\"KPIs exported to 'Adjusted_Yearly_KPIs.csv' and 'Adjusted_Quarterly_KPIs.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b5a87a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Year   Total_Sales  Total_Orders  Total_Returns Sales_Performance  \\\n",
       " 0  2018  5.754557e+05          2441            599           235.75%   \n",
       " 1  2019  5.798728e+05          2522            583           229.93%   \n",
       " 2  2020  7.152204e+05          3179            789           224.98%   \n",
       " 3  2021  1.031128e+06          4278           1255           241.03%   \n",
       " \n",
       "   Sales_Target_Attainment Return_Rate  Sales_Target  \n",
       " 0                    inf%      24.54%       0.00000  \n",
       " 1                  91.61%      23.12%  633001.26131  \n",
       " 2                 112.13%      24.82%  637860.08770  \n",
       " 3                 131.06%      29.34%  786742.41030  ,\n",
       "     Year  Quarter  Total_Sales  Total_Orders  Total_Returns Sales_Performance  \\\n",
       " 0   2018        1   74911.8200           306             34           244.81%   \n",
       " 1   2018        2   88506.1276           414             37           213.78%   \n",
       " 2   2018        3  214885.2383           818            326           262.70%   \n",
       " 3   2018        4  197152.5062           903            202           218.33%   \n",
       " 4   2019        1   82050.3046           324             90           253.24%   \n",
       " 5   2019        2  111723.7890           512            100           218.21%   \n",
       " 6   2019        3  145308.1692           642             77           226.34%   \n",
       " 7   2019        4  240790.5442          1044            316           230.64%   \n",
       " 8   2020        1   98550.8660           373             63           264.21%   \n",
       " 9   2020        2  166683.8860           750            210           222.25%   \n",
       " 10  2020        3  176191.6302           886            192           198.86%   \n",
       " 11  2020        4  273793.9908          1170            324           234.01%   \n",
       " 12  2021        1  178554.2882           632            180           282.52%   \n",
       " 13  2021        2  157658.3571           792            140           199.06%   \n",
       " 14  2021        3  376052.2430          1387            586           271.13%   \n",
       " 15  2021        4  318863.0078          1467            349           217.36%   \n",
       " \n",
       "    Sales_Target_Attainment Return_Rate   Sales_Target  \n",
       " 0                     inf%      11.11%       0.000000  \n",
       " 1                  107.41%       8.94%   82403.002000  \n",
       " 2                  220.72%      39.85%   97356.740360  \n",
       " 3                   83.41%      22.37%  236373.762130  \n",
       " 4                   57.03%      27.78%  143863.923025  \n",
       " 5                   76.71%      19.53%  145648.544175  \n",
       " 6                   95.94%      11.99%  151452.959525  \n",
       " 7                  179.62%      30.27%  134058.692250  \n",
       " 8                   67.98%      16.89%  144968.201750  \n",
       " 9                  111.80%      28.00%  149093.342100  \n",
       " 10                 108.20%      21.67%  162833.366350  \n",
       " 11                 160.53%      27.69%  170554.231600  \n",
       " 12                  99.86%      28.48%  178805.093250  \n",
       " 13                  79.30%      17.68%  198805.948800  \n",
       " 14                 191.33%      42.25%  196549.566575  \n",
       " 15                 129.35%      23.79%  246514.719775  )"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Sales Targets for Yearly KPIs\n",
    "yearly_kpis['Sales_Target'] = 0\n",
    "for i in range(1, len(yearly_kpis)):\n",
    "    yearly_kpis.loc[i, 'Sales_Target'] = yearly_kpis.loc[i-1, 'Total_Sales'] * 1.1\n",
    "\n",
    "# Calculate Sales Targets for Quarterly KPIs\n",
    "quarterly_kpis['Sales_Target'] = 0\n",
    "for i in range(1, 4):\n",
    "    quarterly_kpis.loc[i, 'Sales_Target'] = quarterly_kpis.loc[i-1, 'Total_Sales'] * 1.1\n",
    "for i in range(4, len(quarterly_kpis)):\n",
    "    quarterly_kpis.loc[i, 'Sales_Target'] = (quarterly_kpis.loc[i-4:i-1, 'Total_Sales'].sum()) / 4\n",
    "\n",
    "# Recalculate Sales Target Attainment using the new Sales Targets\n",
    "yearly_kpis['Sales_Target_Attainment'] = (yearly_kpis['Total_Sales'] / yearly_kpis['Sales_Target']) * 100\n",
    "quarterly_kpis['Sales_Target_Attainment'] = (quarterly_kpis['Total_Sales'] / quarterly_kpis['Sales_Target']) * 100\n",
    "\n",
    "# Format the newly calculated 'Sales_Target_Attainment' as percentages with two decimal places\n",
    "yearly_kpis['Sales_Target_Attainment'] = yearly_kpis['Sales_Target_Attainment'].apply(lambda x: f\"{x:.2f}%\")\n",
    "quarterly_kpis['Sales_Target_Attainment'] = quarterly_kpis['Sales_Target_Attainment'].apply(lambda x: f\"{x:.2f}%\")\n",
    "\n",
    "# Export the KPIs to CSV files\n",
    "yearly_kpis.to_csv(\"Final_Adjusted_Yearly_KPIs.csv\", index=False)\n",
    "quarterly_kpis.to_csv(\"Final_Adjusted_Quarterly_KPIs.csv\", index=False)\n",
    "\n",
    "yearly_kpis, quarterly_kpis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6931cac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
