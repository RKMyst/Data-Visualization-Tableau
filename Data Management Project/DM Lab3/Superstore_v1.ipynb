{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3a12c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Row ID        Order ID           Order Date            Ship Date  \\\n",
      "0       1  CA-2020-152156  2020-11-08 00:00:00  2020-11-11 00:00:00   \n",
      "1       2  CA-2020-152156  2020-11-08 00:00:00  2020-11-11 00:00:00   \n",
      "2       3  CA-2020-138688  2020-06-12 00:00:00  2020-06-16 00:00:00   \n",
      "3       4  US-2019-108966  2019-10-11 00:00:00  2019-10-18 00:00:00   \n",
      "4       5  US-2019-108966  2019-10-11 00:00:00  2019-10-18 00:00:00   \n",
      "\n",
      "        Ship Mode Customer ID    Customer Name    Segment Country/Region  \\\n",
      "0    Second Class    CG-12520      Claire Gute   Consumer  United States   \n",
      "1    Second Class    CG-12520      Claire Gute   Consumer  United States   \n",
      "2    Second Class    DV-13045  Darrin Van Huff  Corporate  United States   \n",
      "3  Standard Class    SO-20335   Sean O'Donnell   Consumer  United States   \n",
      "4  Standard Class    SO-20335   Sean O'Donnell   Consumer  United States   \n",
      "\n",
      "              City  ... Postal Code  Region       Product ID         Category  \\\n",
      "0        Henderson  ...     42420.0   South  FUR-BO-10001798        Furniture   \n",
      "1        Henderson  ...     42420.0   South  FUR-CH-10000454        Furniture   \n",
      "2      Los Angeles  ...     90036.0    West  OFF-LA-10000240  Office Supplies   \n",
      "3  Fort Lauderdale  ...     33311.0   South  FUR-TA-10000577        Furniture   \n",
      "4  Fort Lauderdale  ...     33311.0   South  OFF-ST-10000760  Office Supplies   \n",
      "\n",
      "  Sub-Category                                       Product Name     Sales  \\\n",
      "0    Bookcases                  Bush Somerset Collection Bookcase  261.9600   \n",
      "1       Chairs  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400   \n",
      "2       Labels  Self-Adhesive Address Labels for Typewriters b...   14.6200   \n",
      "3       Tables      Bretford CR4500 Series Slim Rectangular Table  957.5775   \n",
      "4      Storage                     Eldon Fold 'N Roll Cart System   22.3680   \n",
      "\n",
      "   Quantity  Discount    Profit  \n",
      "0         2      0.00   41.9136  \n",
      "1         3      0.00  219.5820  \n",
      "2         2      0.00    6.8714  \n",
      "3         5      0.45 -383.0310  \n",
      "4         2      0.20    2.5164  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kei/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py:2779: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  sql.to_sql(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Load the data from the Excel file into a Pandas DataFrame\n",
    "file_name = \"Copy Original Sample - Superstore.xls\"  # Adjust the extension if it's .xlsx\n",
    "df = pd.read_excel(file_name)\n",
    "\n",
    "# Connect to an in-memory SQLite database\n",
    "conn = sqlite3.connect(':memory:')\n",
    "\n",
    "# Write the data to an SQLite table named \"superstore\"\n",
    "df.to_sql('superstore', conn, index=False, if_exists='replace')\n",
    "\n",
    "# Now you can run SQL queries. For example, to fetch the first 5 rows:\n",
    "result = pd.read_sql(\"SELECT * FROM superstore LIMIT 5\", conn)\n",
    "\n",
    "# Display the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e60a183f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining missing postal codes: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kei/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py:2779: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  sql.to_sql(\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create a reference dictionary of cities and their postal codes\n",
    "postal_ref = df.dropna(subset=['Postal Code']).groupby('City')['Postal Code'].first().to_dict()\n",
    "\n",
    "# Step 2: Fill missing postal codes using the reference dictionary\n",
    "def fill_missing_postal(row):\n",
    "    if pd.isnull(row['Postal Code']) and row['City'] in postal_ref:\n",
    "        return postal_ref[row['City']]\n",
    "    return row['Postal Code']\n",
    "\n",
    "df['Postal Code'] = df.apply(fill_missing_postal, axis=1)\n",
    "\n",
    "# Update the SQLite table with the filled data\n",
    "df.to_sql('superstore', conn, index=False, if_exists='replace')\n",
    "\n",
    "# Optional: Check if there are still missing postal codes after the filling process\n",
    "remaining_missing_postal = df['Postal Code'].isnull().sum()\n",
    "print(f\"Remaining missing postal codes: {remaining_missing_postal}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06b5f9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9994 entries, 0 to 9993\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Row ID          9994 non-null   int64         \n",
      " 1   Order ID        9994 non-null   object        \n",
      " 2   Order Date      9994 non-null   datetime64[ns]\n",
      " 3   Ship Date       9994 non-null   datetime64[ns]\n",
      " 4   Ship Mode       9994 non-null   object        \n",
      " 5   Customer ID     9994 non-null   object        \n",
      " 6   Customer Name   9994 non-null   object        \n",
      " 7   Segment         9994 non-null   object        \n",
      " 8   Country/Region  9994 non-null   object        \n",
      " 9   City            9994 non-null   object        \n",
      " 10  State           9994 non-null   object        \n",
      " 11  Postal Code     9994 non-null   float64       \n",
      " 12  Region          9994 non-null   object        \n",
      " 13  Product ID      9994 non-null   object        \n",
      " 14  Category        9994 non-null   object        \n",
      " 15  Sub-Category    9994 non-null   object        \n",
      " 16  Product Name    9994 non-null   object        \n",
      " 17  Sales           9994 non-null   float64       \n",
      " 18  Quantity        9994 non-null   int64         \n",
      " 19  Discount        9994 non-null   float64       \n",
      " 20  Profit          9994 non-null   float64       \n",
      "dtypes: datetime64[ns](2), float64(4), int64(2), object(13)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Display columns and their data types, non-null counts, and other information\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efac1fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Row ID        Order ID Order Date  Ship Date       Ship Mode Customer ID  \\\n",
      "0       1  CA-2020-152156 2020-11-08 2020-11-11    Second Class    CG-12520   \n",
      "1       2  CA-2020-152156 2020-11-08 2020-11-11    Second Class    CG-12520   \n",
      "2       3  CA-2020-138688 2020-06-12 2020-06-16    Second Class    DV-13045   \n",
      "3       4  US-2019-108966 2019-10-11 2019-10-18  Standard Class    SO-20335   \n",
      "4       5  US-2019-108966 2019-10-11 2019-10-18  Standard Class    SO-20335   \n",
      "\n",
      "     Customer Name    Segment Country/Region             City  ... Region  \\\n",
      "0      Claire Gute   Consumer  United States        Henderson  ...  South   \n",
      "1      Claire Gute   Consumer  United States        Henderson  ...  South   \n",
      "2  Darrin Van Huff  Corporate  United States      Los Angeles  ...   West   \n",
      "3   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...  South   \n",
      "4   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...  South   \n",
      "\n",
      "        Product ID         Category Sub-Category  \\\n",
      "0  FUR-BO-10001798        Furniture    Bookcases   \n",
      "1  FUR-CH-10000454        Furniture       Chairs   \n",
      "2  OFF-LA-10000240  Office Supplies       Labels   \n",
      "3  FUR-TA-10000577        Furniture       Tables   \n",
      "4  OFF-ST-10000760  Office Supplies      Storage   \n",
      "\n",
      "                                        Product Name     Sales Quantity  \\\n",
      "0                  Bush Somerset Collection Bookcase  261.9600        2   \n",
      "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400        3   \n",
      "2  Self-Adhesive Address Labels for Typewriters b...   14.6200        2   \n",
      "3      Bretford CR4500 Series Slim Rectangular Table  957.5775        5   \n",
      "4                     Eldon Fold 'N Roll Cart System   22.3680        2   \n",
      "\n",
      "   Discount    Profit  Returned  \n",
      "0      0.00   41.9136     False  \n",
      "1      0.00  219.5820     False  \n",
      "2      0.00    6.8714     False  \n",
      "3      0.45 -383.0310     False  \n",
      "4      0.20    2.5164     False  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the \"Orders\" and \"Returns\" spreadsheets into separate DataFrames\n",
    "df_orders = pd.read_excel(file_name, sheet_name=\"Orders\")\n",
    "df_returns = pd.read_excel(file_name, sheet_name=\"Returns\")\n",
    "\n",
    "# Merge the two DataFrames based on the \"Order ID\" column\n",
    "merged_df = pd.merge(df_orders, df_returns, on=\"Order ID\", how=\"left\")\n",
    "\n",
    "# Create a new column \"Returned\" which will indicate if an order was returned or not\n",
    "merged_df['Returned'] = merged_df['Returned'].notna()\n",
    "\n",
    "# If needed, you can save the merged dataframe back to an Excel file\n",
    "# merged_df.to_excel(\"Merged_Superstore.xls\", index=False)\n",
    "\n",
    "# Display the first few rows of the merged dataframe\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58ec5bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to Merged_Superstore.csv\n"
     ]
    }
   ],
   "source": [
    "# Export the merged dataframe to a CSV file\n",
    "file_name_export = \"Merged_Superstore.csv\"\n",
    "merged_df.to_csv(file_name_export, index=False)\n",
    "\n",
    "print(f\"Data exported to {file_name_export}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c758a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
